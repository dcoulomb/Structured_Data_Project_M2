{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output Prediction of Anti-Cancer Drug Activity\n",
    "\n",
    "Anas Atmani, Beno√Æt Choffin, Domitille Coulomb, Paul Roujansky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- We consider 2305 distinct molecules. Each of them has several physico-chemical and geometric properties that enables to build similarities between all molecules through a kernel. We end up with the (2305x2305) Gram matrix of the Tanimoto kernel.\n",
    "\n",
    "**Ouput:**\n",
    "\n",
    "- We have a total of 59 cancer cell lines for which we would like to predict the effect of each molecule (active/inactive). This last information is provided in a (2305x59) \"target\" matrix.\n",
    "\n",
    "- We also have external RNA-based data for each cancer cell line. By computing the (59x59) correlation matrix based on these features, we build a similarity graph between all cancer cell lines through a *maximum weight spanning tree* (MWST). As a quick note, the graph should not necesarrily be fully-connected which should considerably reduce computation time.\n",
    "\n",
    "### Modelling\n",
    "\n",
    "Two approaches:\n",
    "\n",
    "- take into account the similarities between the cancer cell lines and make use of this \"structure\" (goal of the article) through a MMCRF algorithm.\n",
    "- perform prediction indepently for each cancer cell line, through a standard classification algortihm such as SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncicancer_input_kernel.txt loaded.\n",
      "ncicancer_bin_targets.txt loaded.\n",
      "ncicancer_targets.txt loaded.\n",
      "ncicancer_cancerCL_corr.txt loaded.\n"
     ]
    }
   ],
   "source": [
    "file_names = ['ncicancer_input_kernel.txt',\n",
    "            'ncicancer_bin_targets.txt',\n",
    "            'ncicancer_targets.txt',\n",
    "            'ncicancer_cancerCL_corr.txt']\n",
    "\n",
    "data = []\n",
    "\n",
    "' We import each dataset and append it to the list \"data\" '\n",
    "for file in file_names:\n",
    "    try:\n",
    "        data.append(np.loadtxt('data_clean/'+file))\n",
    "        print('%s loaded.' %file)\n",
    "    except:\n",
    "        print('Error: %s not loaded.' %file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' We define the variables '\n",
    "X_gram = data[0]\n",
    "Y_class = data[1]\n",
    "Y_reg = data[2]\n",
    "cancer_correls = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2305, 2305), (2305, 59), (2305, 59), (59, 59))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' We check the shape of each variable '\n",
    "X_gram.shape, Y_class.shape, Y_reg.shape, cancer_correls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class partition():\n",
    "    \n",
    "    def __init__(self, n_splits=3, shuffle=False):\n",
    "        '''\n",
    "        - \"n_splits\"  number of folds (at least 2)\n",
    "        - \"shuffle\"   boolean which states whether to shuffle the data or not before splitting into batches\n",
    "        '''\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def get_splits(self, n):\n",
    "        '''\n",
    "        Compute the partition (indices contained in each folds)\n",
    "        '''\n",
    "        self.n = n\n",
    "        \n",
    "        self.idx = np.arange(self.n)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idx)\n",
    "        \n",
    "        self.l = int(self.n/self.n_splits)\n",
    "        \n",
    "        self.partition = []\n",
    "        self.partition = [self.idx[j*self.l:(j+1)*self.l] for j in range(self.n_splits-1)]\n",
    "        self.partition.append(self.idx[(self.n_splits-1)*self.l:])\n",
    "    \n",
    "    def split(self, i, X, y):\n",
    "        '''\n",
    "        Performs k-fold with:\n",
    "        - \"i\"   index of the split in the index partition\n",
    "        - \"X\"   Gram (n*n) matrix\n",
    "        - \"y\"   output (n*m) matrix (m outputs)\n",
    "        '''\n",
    "        \n",
    "        idx_train = np.concatenate([self.partition[k] for k in range(self.n_splits) if k!=i])\n",
    "        \n",
    "        idx_test = self.partition[i]\n",
    "        X_train = X[idx_train,:][:,idx_train]\n",
    "        y_train = y[idx_train,:]\n",
    "        X_test = X[idx_test,:][:,idx_train] # CAREFUL !\n",
    "        y_test = y[idx_test,:]\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class k_fold_CV():\n",
    "    \n",
    "    def __init__(self, C, n_splits, shuffle):\n",
    "        '''\n",
    "        - \"C\"         SVM hyperparameter\n",
    "        - \"n_splits\"  number of folds of the k-fold cross validation (at least 2)\n",
    "        - \"shuffle\"   boolean which states whether to shuffle the data or not before splitting into batches\n",
    "        '''\n",
    "        self.C = C\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.trained = False\n",
    "        \n",
    "    def fit_predict(self, X, y, verbose=True):\n",
    "        \n",
    "        self.n, self.m = y.shape\n",
    "        ' we build \"n_splits\" folds '\n",
    "        kFold = partition(n_splits=self.n_splits, shuffle=self.shuffle)\n",
    "        kFold.get_splits(y.shape[0])\n",
    "        shuffled_y = y[kFold.idx,:]\n",
    "        \n",
    "        model = SVC(C=100, kernel='precomputed')\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Fold \\t Computation time\")\n",
    "        \n",
    "        for k in range(self.n_splits):\n",
    "            ' we perform k-fold cross validation '\n",
    "            startTime = time.time()\n",
    "            \n",
    "            ' we create the synthetic train and test datasets '\n",
    "            X_train, y_train, X_test, y_test = kFold.split(k, X, y)\n",
    "            \n",
    "            Y_preds_j = []\n",
    "            \n",
    "            for j in range(y.shape[1]):\n",
    "                ' we train j distinct models for each cancer cell line '\n",
    "                model.fit(X_train, y_train[:,j])\n",
    "                ' we stack the results iteratively '\n",
    "                Y_preds_j.append(model.predict(X_test))\n",
    "            \n",
    "            ' We stack the results obtained for each fold '\n",
    "            if k==0:\n",
    "                Y_preds = np.array(Y_preds_j).T\n",
    "            else:\n",
    "                Y_preds = np.concatenate((Y_preds, np.array(Y_preds_j).T))\n",
    "        \n",
    "            runTime = time.time() - startTime\n",
    "            if verbose:\n",
    "                print(\"%d/%d \\t %d\" %(k+1, self.n_splits, runTime))\n",
    "        \n",
    "        ' we calculate the classification error '\n",
    "        self.accuracies = np.array([accuracy_score(Y_preds[:,i], shuffled_y[:,i]) for i in range(Y_preds.shape[1])])\n",
    "        self.trained = True\n",
    "        \n",
    "        \n",
    "    def results(self):\n",
    "        \n",
    "        if self.trained:\n",
    "            print(\"Results for %d folds on the full dataset:\" %self.n_splits)\n",
    "            print(\"Average = %.2f%%\" %(np.mean(self.accuracies)*100))\n",
    "            print(\"Standard deviation = %.2f%%\" %(np.std(self.accuracies)*100))\n",
    "        else:\n",
    "            print(\"Not trained yet.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = k_fold_CV(C=100, n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold \t Computation time\n",
      "1/5 \t 17\n",
      "2/5 \t 17\n",
      "3/5 \t 16\n",
      "4/5 \t 16\n",
      "5/5 \t 17\n"
     ]
    }
   ],
   "source": [
    "model.fit_predict(X_gram, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 5 folds on the full dataset:\n",
      "Average = 76.63%\n",
      "Standard deviation = 3.93%\n"
     ]
    }
   ],
   "source": [
    "model.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
